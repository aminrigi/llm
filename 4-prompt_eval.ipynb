{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "000b598e",
   "metadata": {},
   "source": [
    "Set up and load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40af9ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fbb977",
   "metadata": {},
   "source": [
    "#### 0- Load VecDB and transforming into a retriver interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7259c42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = HuggingFaceEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "vectordb = Chroma(persist_directory=\"./chroma_db\", embedding_function=embedding)\n",
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198607ac",
   "metadata": {},
   "source": [
    "### 1- Define Prompt Logic\n",
    "\n",
    "- temperature: Controls randomness in generation. Lower values make the output more deterministic, while higher values increase diversity.\n",
    "- top_k: Limits the number of highest-probability tokens considered during generation.\n",
    "- top_p: Implements nucleus sampling, where only tokens with cumulative probability p are considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2dc6cc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"Use the following context to answer the question. Be concise and accurate.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "llm_pipeline = pipeline(\"text2text-generation\", \n",
    "                        model=AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\"), \n",
    "                        tokenizer=AutoTokenizer.from_pretrained(\"google/flan-t5-base\"),\n",
    "                        max_new_tokens=100,\n",
    "                        )\n",
    "llm = HuggingFacePipeline(pipeline=llm_pipeline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0228509e",
   "metadata": {},
   "source": [
    "| Parameter            | Range         | Purpose/Effect                                                                 | Recommended Values by Use Case         |\n",
    "|----------------------|---------------|--------------------------------------------------------------------------------|----------------------------------------|\n",
    "| **Temperature**      | 0.0 ‚Äì 1.0     | Controls randomness. Lower = more deterministic; higher = more creative.      | - Deterministic: `0.2`<br>- Balanced: `0.5`<br>- Creative: `0.9` |\n",
    "| **Top-k**            | 1 ‚Äì 50        | Limits sampling to top-k tokens. Lower = focused; higher = diverse.           | - Deterministic: `5`<br>- Balanced: `20`<br>- Creative: `40`     |\n",
    "| **Top-p**            | 0.0 ‚Äì 1.0     | Nucleus sampling. Lower = deterministic; higher = creative.                   | - Deterministic: `0.3`<br>- Balanced: `0.6`<br>- Creative: `0.9` |\n",
    "| **Repetition Penalty** | 1.0 ‚Äì 2.0   | Penalizes repeated tokens. Higher = less repetition.                          | - Deterministic: `1.0`<br>- Balanced: `1.2`<br>- Creative: `1.5` |\n",
    "\n",
    "\n",
    "### 2- Interface and prompting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f44b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1634 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is best approach to deal with missing val...</td>\n",
       "      <td>Forward fill.</td>\n",
       "      <td>One\\tof\\tthe\\tsimplest\\tways\\tto\\tfill\\tin\\tmi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What features are important for time series?</td>\n",
       "      <td>(4).</td>\n",
       "      <td>Chapter\\t8.\\t Generating\\tand\\tSelecting\\nFeat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the purpose of time series analysis?</td>\n",
       "      <td>Extracting meaningful summary and statistical ...</td>\n",
       "      <td>\\ta\\tsurfeit\\tof\\nfeatures\\tthan\\tit\\tis\\tto\\t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is best approach to deal with missing val...   \n",
       "1       What features are important for time series?   \n",
       "2       What is the purpose of time series analysis?   \n",
       "\n",
       "                                              answer  \\\n",
       "0                                      Forward fill.   \n",
       "1                                               (4).   \n",
       "2  Extracting meaningful summary and statistical ...   \n",
       "\n",
       "                                             context  \n",
       "0  One\\tof\\tthe\\tsimplest\\tways\\tto\\tfill\\tin\\tmi...  \n",
       "1  Chapter\\t8.\\t Generating\\tand\\tSelecting\\nFeat...  \n",
       "2  \\ta\\tsurfeit\\tof\\nfeatures\\tthan\\tit\\tis\\tto\\t...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": prompt_template}\n",
    ")\n",
    "\n",
    "questions = [\n",
    "    \"What is best approach to deal with missing values?\",\n",
    "    \"What features are important for time series?\",\n",
    "    \"What is the purpose of time series analysis?\"\n",
    "]\n",
    "\n",
    "results = []\n",
    "for q in questions:\n",
    "    res = qa_chain.invoke({\"query\": q})  \n",
    "    results.append({\n",
    "        \"question\": q,\n",
    "        \"answer\": res['result'],\n",
    "        \"context\": res['source_documents'][0].page_content if res['source_documents'] else \"N/A\"\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff2753e",
   "metadata": {},
   "source": [
    "### 3- Evaluation\n",
    "\n",
    "\n",
    "| **Metric**              | **Measures**                             | **Strengths**                                                                | **Limitations**                                                       | **Scoring Range**  | **Ideal Use Cases**                      | **Implementation Notes**                                     |\n",
    "| ----------------------- | ---------------------------------------- | ---------------------------------------------------------------------------- | --------------------------------------------------------------------- | ------------------ | ---------------------------------------- | ------------------------------------------------------------ |\n",
    "| **String Similarity**   | Character-level sequence overlap         | Fast, simple, interpretable                                                  | Sensitive to word order; ignores semantics                            | 0 to 1             | Quick sanity checks, small tweaks        | Uses `difflib.SequenceMatcher` in Python                     |\n",
    "| **BLEU**                | N-gram precision (1‚Äì4 grams)             | Widely used in machine translation, captures short patterns                  | Favors shorter outputs; penalizes valid rephrasings                   | 0 to 1             | Factual Q\\&A, summaries with gold labels | Use Hugging Face `evaluate` library                          |\n",
    "| **ROUGE-L**             | Longest common subsequence               | Good for content overlap and partial matches                                 | Sensitive to formatting and verbosity                                 | 0 to 1             | Summarization, Q\\&A                      | `rougeL` is best suited for factual or summary comparison    |\n",
    "| **Semantic Similarity** | Cosine similarity of sentence embeddings | Captures paraphrasing, semantically close responses                          | Can be tricked by verbose, vague, or generic answers                  | ‚Äì1 to 1            | Open-ended answers, QA with synonyms     | Use `sentence-transformers` with `cos_sim`                   |\n",
    "| **LLM-as-a-Judge**      | Scored by an LLM based on custom prompt  | Human-like judgment; considers coherence, completeness, and factual accuracy | Subjective; expensive (API calls); inconsistent without prompt tuning | 0 to 5 (or custom) | High-stakes eval, human-like ranking     | Requires well-crafted prompts; best for few-shot comparisons |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**3.1- String similarity: Simple similarity match with ground truth**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c77e47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is best approach to deal with missing val...</td>\n",
       "      <td>Forward fill.</td>\n",
       "      <td>A framework for building LLM applications.</td>\n",
       "      <td>0.290909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What features are important for time series?</td>\n",
       "      <td>(4).</td>\n",
       "      <td>A method to retrieve documents based on vector...</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the purpose of time series analysis?</td>\n",
       "      <td>Extracting meaningful summary and statistical ...</td>\n",
       "      <td>To split large text into manageable and semant...</td>\n",
       "      <td>0.080268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is best approach to deal with missing val...   \n",
       "1       What features are important for time series?   \n",
       "2       What is the purpose of time series analysis?   \n",
       "\n",
       "                                              answer  \\\n",
       "0                                      Forward fill.   \n",
       "1                                               (4).   \n",
       "2  Extracting meaningful summary and statistical ...   \n",
       "\n",
       "                                    reference_answer  similarity  \n",
       "0         A framework for building LLM applications.    0.290909  \n",
       "1  A method to retrieve documents based on vector...    0.032258  \n",
       "2  To split large text into manageable and semant...    0.080268  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can optionally add ground truth comparison if available\n",
    "df[\"reference_answer\"] = [\n",
    "    \"A framework for building LLM applications.\",\n",
    "    \"A method to retrieve documents based on vector similarity.\",\n",
    "    \"To split large text into manageable and semantically meaningful pieces.\"\n",
    "]\n",
    "\n",
    "# Simple string similarity score\n",
    "from difflib import SequenceMatcher\n",
    "df[\"similarity\"] = df.apply(lambda row: SequenceMatcher(None, row[\"answer\"], row[\"reference_answer\"]).ratio(), axis=1)\n",
    "df[[\"question\", \"answer\", \"reference_answer\", \"similarity\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a806dc3f",
   "metadata": {},
   "source": [
    "**3.2- BLEU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45af71bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "043850630a5640da8d94fcc3f738f9bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df73841603649f9bad5df2c4bffdb54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb882a52c6f54278b25901d2100ab952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is best approach to deal with missing val...</td>\n",
       "      <td>Forward fill.</td>\n",
       "      <td>A framework for building LLM applications.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What features are important for time series?</td>\n",
       "      <td>(4).</td>\n",
       "      <td>A method to retrieve documents based on vector...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the purpose of time series analysis?</td>\n",
       "      <td>Extracting meaningful summary and statistical ...</td>\n",
       "      <td>To split large text into manageable and semant...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is best approach to deal with missing val...   \n",
       "1       What features are important for time series?   \n",
       "2       What is the purpose of time series analysis?   \n",
       "\n",
       "                                              answer  \\\n",
       "0                                      Forward fill.   \n",
       "1                                               (4).   \n",
       "2  Extracting meaningful summary and statistical ...   \n",
       "\n",
       "                                    reference_answer  bleu  \n",
       "0         A framework for building LLM applications.   0.0  \n",
       "1  A method to retrieve documents based on vector...   0.0  \n",
       "2  To split large text into manageable and semant...   0.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "df[\"bleu\"] = df.apply(lambda row: bleu.compute(predictions=[row[\"answer\"]], references=[[row[\"reference_answer\"]]])[\"bleu\"], axis=1)\n",
    "\n",
    "df[[\"question\", \"answer\", \"reference_answer\", \"bleu\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dfc9e9",
   "metadata": {},
   "source": [
    "**3.3- Rouge**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c94ff9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>bleu</th>\n",
       "      <th>rougeL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is best approach to deal with missing val...</td>\n",
       "      <td>Forward fill.</td>\n",
       "      <td>A framework for building LLM applications.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What features are important for time series?</td>\n",
       "      <td>(4).</td>\n",
       "      <td>A method to retrieve documents based on vector...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the purpose of time series analysis?</td>\n",
       "      <td>Extracting meaningful summary and statistical ...</td>\n",
       "      <td>To split large text into manageable and semant...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is best approach to deal with missing val...   \n",
       "1       What features are important for time series?   \n",
       "2       What is the purpose of time series analysis?   \n",
       "\n",
       "                                              answer  \\\n",
       "0                                      Forward fill.   \n",
       "1                                               (4).   \n",
       "2  Extracting meaningful summary and statistical ...   \n",
       "\n",
       "                                    reference_answer  bleu    rougeL  \n",
       "0         A framework for building LLM applications.   0.0  0.000000  \n",
       "1  A method to retrieve documents based on vector...   0.0  0.000000  \n",
       "2  To split large text into manageable and semant...   0.0  0.043956  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge = evaluate.load(\"rouge\")\n",
    "df[\"rougeL\"] = df.apply(lambda row: rouge.compute(predictions=[row[\"answer\"]], references=[row[\"reference_answer\"]])[\"rougeL\"], axis=1)\n",
    "df[[\"question\", \"answer\", \"reference_answer\", \"bleu\", \"rougeL\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0466c6e5",
   "metadata": {},
   "source": [
    "**3.4- Semantic Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12ef863d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>semantic_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is best approach to deal with missing val...</td>\n",
       "      <td>Forward fill.</td>\n",
       "      <td>A framework for building LLM applications.</td>\n",
       "      <td>0.056915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What features are important for time series?</td>\n",
       "      <td>(4).</td>\n",
       "      <td>A method to retrieve documents based on vector...</td>\n",
       "      <td>-0.025989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the purpose of time series analysis?</td>\n",
       "      <td>Extracting meaningful summary and statistical ...</td>\n",
       "      <td>To split large text into manageable and semant...</td>\n",
       "      <td>0.148686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is best approach to deal with missing val...   \n",
       "1       What features are important for time series?   \n",
       "2       What is the purpose of time series analysis?   \n",
       "\n",
       "                                              answer  \\\n",
       "0                                      Forward fill.   \n",
       "1                                               (4).   \n",
       "2  Extracting meaningful summary and statistical ...   \n",
       "\n",
       "                                    reference_answer  semantic_similarity  \n",
       "0         A framework for building LLM applications.             0.056915  \n",
       "1  A method to retrieve documents based on vector...            -0.025989  \n",
       "2  To split large text into manageable and semant...             0.148686  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "df[\"semantic_similarity\"] = df.apply(lambda row: util.cos_sim(\n",
    "    model.encode(row[\"answer\"], convert_to_tensor=True),\n",
    "    model.encode(row[\"reference_answer\"], convert_to_tensor=True)\n",
    ").item(), axis=1)\n",
    "\n",
    "df[[\"question\", \"answer\", \"reference_answer\", \"semantic_similarity\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb10e2d",
   "metadata": {},
   "source": [
    "**3.5- LLM as a judge**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8700f9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>llm_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is best approach to deal with missing val...</td>\n",
       "      <td>Forward fill.</td>\n",
       "      <td>A framework for building LLM applications.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What features are important for time series?</td>\n",
       "      <td>(4).</td>\n",
       "      <td>A method to retrieve documents based on vector...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the purpose of time series analysis?</td>\n",
       "      <td>Extracting meaningful summary and statistical ...</td>\n",
       "      <td>To split large text into manageable and semant...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is best approach to deal with missing val...   \n",
       "1       What features are important for time series?   \n",
       "2       What is the purpose of time series analysis?   \n",
       "\n",
       "                                              answer  \\\n",
       "0                                      Forward fill.   \n",
       "1                                               (4).   \n",
       "2  Extracting meaningful summary and statistical ...   \n",
       "\n",
       "                                    reference_answer llm_score  \n",
       "0         A framework for building LLM applications.         0  \n",
       "1  A method to retrieve documents based on vector...         4  \n",
       "2  To split large text into manageable and semant...         3  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grading prompt\n",
    "\n",
    "grading_prompt = \"\"\"\n",
    "You are a strict evaluator. Given a question, a reference answer, and a model-generated answer, score the model's answer from 0 to 5 based on how accurate and complete it is.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Reference Answer: {reference}\n",
    "Model Answer: {model_answer}\n",
    "\n",
    "Score (0 to 5):\n",
    "\"\"\"\n",
    "\n",
    "def llm_grade(row):\n",
    "    input_text = grading_prompt.format(\n",
    "        question=row[\"question\"],\n",
    "        reference=row[\"reference_answer\"],\n",
    "        model_answer=row[\"answer\"]\n",
    "    )\n",
    "    return llm_pipeline(input_text)[0][\"generated_text\"]\n",
    "\n",
    "df[\"llm_score\"] = df.apply(llm_grade, axis=1)\n",
    "df[[\"question\", \"answer\", \"reference_answer\", \"llm_score\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd33772",
   "metadata": {},
   "source": [
    "\n",
    "# üß† Productionizing a RAG System (One-Pager)\n",
    "\n",
    "## üß© Architecture Overview\n",
    "```\n",
    "1. Document Ingestion\n",
    "        ‚Üì\n",
    "2. Chunking & Embedding (sentence-transformers)\n",
    "        ‚Üì\n",
    "3. Store in Vector DB (Qdrant / Weaviate)\n",
    "        ‚Üì\n",
    "4. Query Handling + Retrieval (LangChain Retriever)\n",
    "        ‚Üì\n",
    "5. Prompt Injection + LLM Inference (flan-t5 / mistral + vLLM)\n",
    "        ‚Üì\n",
    "6. Evaluation (BLEU / ROUGE / Semantic Similarity)\n",
    "        ‚Üì\n",
    "7. Feedback Loop + Monitoring\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è Key Components & Tools\n",
    "\n",
    "| Component           | Description                                                  | Recommended Tech                                      |\n",
    "|--------------------|--------------------------------------------------------------|-------------------------------------------------------|\n",
    "| **Chunking**        | Split documents into semantic chunks                         | LangChain, Unstructured                              |\n",
    "| **Embedding**       | Encode chunks into dense vectors                             | `BAAI/bge-base`, `MiniLM`, `instructor-xl`           |\n",
    "| **Vector Store**    | Store & retrieve embeddings                                  | Qdrant, Weaviate, Chroma (dev), FAISS                |\n",
    "| **Retriever**       | Top-k / MMR retrieval of context                             | LangChain, Haystack                                  |\n",
    "| **Prompting**       | Custom templates to guide LLM output                         | LangChain PromptTemplate                             |\n",
    "| **LLM Inference**   | Generate answer from context + query                         | flan-t5, mistral, LLaMA2 via vLLM or TGI             |\n",
    "| **Evaluation**      | Assess answer quality                                        | BLEU, ROUGE, Semantic Similarity, LLM-as-a-Judge     |\n",
    "| **Serving API**     | Handle external queries                                      | FastAPI, Flask, LangServe                            |\n",
    "| **Deployment**      | Orchestrate and scale system                                 | Docker, K8s, Terraform, GitHub Actions               |\n",
    "| **Monitoring**      | Track performance & detect drift                             | Prometheus, Grafana, LangSmith, Evidently            |\n",
    "\n",
    "---\n",
    "\n",
    "## üîÅ Feedback Loop\n",
    "\n",
    "- Capture user feedback (thumbs up/down)\n",
    "- Log question + context + answer + feedback\n",
    "- Fine-tune embedding model or LLM based on evaluation drift\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Deployment Flow (CI/CD)\n",
    "\n",
    "1. Develop in Jupyter or VSCode (unit tested)\n",
    "2. Containerize with Docker\n",
    "3. Deploy via GitHub Actions or Terraform to K8s / SageMaker\n",
    "4. Monitor endpoints and vector drift\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
