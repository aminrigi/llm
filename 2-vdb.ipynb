{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16c6bfe5",
   "metadata": {},
   "source": [
    "## Vector DB\n",
    "\n",
    "### 1- Embedding Model Selection\n",
    "\n",
    "One crucial step is choosing the right embedding model that support the characteritics of our chunks profile particularly max tokens. OpenAIEmbedding takes care of it, but if we hand select the models it becomes important which model we are using. Below is the chunk stats from step 1. \n",
    "\n",
    "| Metric         | Characters         | Tokens             |\n",
    "|----------------|--------------------|--------------------|\n",
    "| Minimum        | 172                | 58                 |\n",
    "| Maximum        | 2472               | 746                |\n",
    "| Mean           | 1625.64            | 500.89             |\n",
    "| Median         | 1840.0             | 579.0              |\n",
    "| Standard Dev.  | 639.48             | 193.15             |\n",
    "| Number of Chunks | **579**          | **579**            |\n",
    "\n",
    "\n",
    "(**Domain Specific Embedding:** We can use do domain specific embedding models. And test it out.)\n",
    "\n",
    "\n",
    "Here, I don't want to use API. Based on average chunk size (~500‚Äì750 tokens), we use: **BAAI/bge-base-en-v1.5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c632d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-base-en-v1.5\",\n",
    "    model_kwargs={'device': 'cpu'},  # or 'cuda' if available\n",
    "    encode_kwargs={'normalize_embeddings': True}  # for cosine search\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e409ba8a",
   "metadata": {},
   "source": [
    "### 2- Create and Persist Chroma Vector Store\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2e8a533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 579 chunks\n",
      "‚úÖ Chroma vector store saved to 'chroma_db'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rigia\\AppData\\Local\\Temp\\ipykernel_20452\\2558069247.py:23: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  chroma_db.persist()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Load Chunks\n",
    "import pickle\n",
    "\n",
    "with open(\"data/chunks.pkl\", \"rb\") as f:\n",
    "    token_chunks = pickle.load(f)\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(token_chunks)} chunks\")\n",
    "\n",
    "\n",
    "\n",
    "## Create and persist the Chroma vector store\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "chroma_db = Chroma.from_documents(\n",
    "    documents=token_chunks,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=\"chroma_db\",\n",
    "        collection_metadata={\n",
    "        \"hnsw:space\": \"cosine\"  # Set the similarity metric\n",
    "    }\n",
    ")\n",
    "\n",
    "chroma_db.persist()\n",
    "print(\"‚úÖ Chroma vector store saved to 'chroma_db'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378a5848",
   "metadata": {},
   "source": [
    "### 3- Querying Chroma DB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ae7f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_db = Chroma(\n",
    "    persist_directory=\"chroma_db\",\n",
    "    embedding_function=embedding_model,\n",
    "    collection_metadata={\n",
    "        \"hnsw:space\": \"cosine\"  # Set the similarity metric\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ee62031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîé Result 1\n",
      "One\tof\tthe\tsimplest\tways\tto\tfill\tin\tmissing\tvalues\tis\tto\tcarry\tforward\tthe\tlast\tknown\tvalue\tprior\n",
      "to\tthe\tmissing\tone,\tan\tapproach\tknown\tas\t\n",
      "forward\tfill\n",
      ".\tNo\tmathematics\tor\tcomplicated\tlogic\tis\n",
      "required.\tSimply\tconsider\tthe\texperience\tof\tmoving\tforward\tin\ttime\twith\tthe\tdata\tthat\twas\n",
      "available,\tand\ty\n",
      "Metadata: {'creationdate': '2020-03-30T07:09:46+00:00', 'page_label': '38', 'source': 'data/ps.pdf', 'page': 37, 'producer': 'PDF Candy', 'moddate': '2020-03-30T07:09:46+00:00', 'total_pages': 365, 'creator': 'PyPDF'}\n",
      "\n",
      "üîé Result 2\n",
      "One\tof\tthe\tsimplest\tways\tto\tfill\tin\tmissing\tvalues\tis\tto\tcarry\tforward\tthe\tlast\tknown\tvalue\tprior\n",
      "to\tthe\tmissing\tone,\tan\tapproach\tknown\tas\t\n",
      "forward\tfill\n",
      ".\tNo\tmathematics\tor\tcomplicated\tlogic\tis\n",
      "required.\tSimply\tconsider\tthe\texperience\tof\tmoving\tforward\tin\ttime\twith\tthe\tdata\tthat\twas\n",
      "available,\tand\ty\n",
      "Metadata: {'page_label': '38', 'creator': 'PyPDF', 'source': 'data/ps.pdf', 'total_pages': 365, 'producer': 'PDF Candy', 'creationdate': '2020-03-30T07:09:46+00:00', 'page': 37, 'moddate': '2020-03-30T07:09:46+00:00'}\n",
      "\n",
      "üîé Result 3\n",
      "Figure\t2-9.\t\n",
      "The\tdashed\tline\tshows\tthe\tlinear\tinterpolation\twhile\tthe\tdotted\tline\tshows\tthe\tspline\n",
      "interpolation.\n",
      "There\tare\tmany\tsituations\twhere\ta\tlinear\t(or\tspline)\tinterpolation\tis\tappropriate.\tConsider\tmean\n",
      "average\tweekly\ttemperature\twhere\tthere\tis\ta\tknown\ttrend\tof\trising\tor\tfalling\ttemperatures\n",
      "Metadata: {'producer': 'PDF Candy', 'creationdate': '2020-03-30T07:09:46+00:00', 'moddate': '2020-03-30T07:09:46+00:00', 'creator': 'PyPDF', 'page_label': '42', 'source': 'data/ps.pdf', 'page': 41, 'total_pages': 365}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query = \"How does the model deal with missing values?\"\n",
    "results = chroma_db.similarity_search(query, k=3)\n",
    "\n",
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\nüîé Result {i+1}\")\n",
    "    print(doc.page_content[:300])  # Preview first 300 chars\n",
    "    print(\"Metadata:\", doc.metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8536ebaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rigia\\AppData\\Local\\Temp\\ipykernel_28976\\3544454756.py:1: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  chroma_db = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîé Result 1\n",
      "One\tof\tthe\tsimplest\tways\tto\tfill\tin\tmissing\tvalues\tis\tto\tcarry\tforward\tthe\tlast\tknown\tvalue\tprior\n",
      "to\tthe\tmissing\tone,\tan\tapproach\tknown\tas\t\n",
      "forward\tfill\n",
      ".\tNo\tmathematics\tor\tcomplicated\tlogic\tis\n",
      "required.\tSimply\tconsider\tthe\texperience\tof\tmoving\tforward\tin\ttime\twith\tthe\tdata\tthat\twas\n",
      "available,\tand\ty\n",
      "Metadata: {'producer': 'PDF Candy', 'source': 'data/ps.pdf', 'page': 37, 'page_label': '38', 'creationdate': '2020-03-30T07:09:46+00:00', 'moddate': '2020-03-30T07:09:46+00:00', 'creator': 'PyPDF', 'total_pages': 365}\n",
      "\n",
      "üîé Result 2\n",
      "Figure\t2-9.\t\n",
      "The\tdashed\tline\tshows\tthe\tlinear\tinterpolation\twhile\tthe\tdotted\tline\tshows\tthe\tspline\n",
      "interpolation.\n",
      "There\tare\tmany\tsituations\twhere\ta\tlinear\t(or\tspline)\tinterpolation\tis\tappropriate.\tConsider\tmean\n",
      "average\tweekly\ttemperature\twhere\tthere\tis\ta\tknown\ttrend\tof\trising\tor\tfalling\ttemperatures\n",
      "Metadata: {'page_label': '42', 'page': 41, 'creator': 'PyPDF', 'source': 'data/ps.pdf', 'moddate': '2020-03-30T07:09:46+00:00', 'producer': 'PDF Candy', 'total_pages': 365, 'creationdate': '2020-03-30T07:09:46+00:00'}\n",
      "\n",
      "üîé Result 3\n",
      "Remember\tthat\tmany\tof\tthe\tpreceding\tmethods\tinclude\ta\tlookahead.\tThe\tonly\tmethods\tthat\tdo\n",
      "not\tare\tthe\tforward\tfill\tand\tthe\tmoving\taverage\twithout\ta\tlookahead\t(there\tis\talso\ta\tmoving\n",
      "average\twith\ta\tlookahead).\tFor\tthis\treason,\tit‚Äôs\tnot\tsurprising\tthat\tthere\tis\ta\trange\tof\tdifference\n",
      "in\terrors\tand\tthat\n",
      "Metadata: {'page': 42, 'page_label': '43', 'producer': 'PDF Candy', 'creator': 'PyPDF', 'moddate': '2020-03-30T07:09:46+00:00', 'creationdate': '2020-03-30T07:09:46+00:00', 'total_pages': 365, 'source': 'data/ps.pdf'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query = \"How does the model deal with missing values?\"\n",
    "results = chroma_db.similarity_search(query, k=3)\n",
    "\n",
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\nüîé Result {i+1}\")\n",
    "    print(doc.page_content[:300])  # Preview first 300 chars\n",
    "    print(\"Metadata:\", doc.metadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3cb6a6",
   "metadata": {},
   "source": [
    "## 4- Comparing different vector databases\n",
    "\n",
    "| Vector DB   | Open Source | Index Types Supported      | Metadata Filtering | Hybrid Search        | LangChain Support | Best Use Case                                     |\n",
    "|-------------|-------------|-----------------------------|---------------------|-----------------------|--------------------|--------------------------------------------------|\n",
    "| **Chroma**  | ‚úÖ Yes      | HNSW-like ANN               | ‚úÖ Yes              | ‚ùå No                | ‚úÖ Native          | Local dev, rapid prototyping, simple pipelines   |\n",
    "| **FAISS**   | ‚úÖ Yes      | Flat, IVF, PQ, HNSW, OPQ    | ‚ùå No               | ‚ùå No                | ‚úÖ Full            | In-memory high-speed search, no metadata needed  |\n",
    "| **Weaviate**| ‚úÖ Yes      | HNSW + optional BM25 Hybrid | ‚úÖ Yes              | ‚úÖ Yes (BM25 + Vector)| ‚úÖ Native          | Hybrid semantic + keyword retrieval at scale     |\n",
    "\n",
    "HNSW ANN: Graph based Approximate Neearest Neighbour\n",
    "\n",
    "### Index Type Comparison:\n",
    "\n",
    "| Index Type | Type    | Description                                                                 | Accuracy        | Speed         | Memory Usage | Time Complexity     | Best Use Case                                         |\n",
    "|------------|---------|-----------------------------------------------------------------------------|------------------|---------------|--------------|----------------------|--------------------------------------------------------|\n",
    "| **Flat**   | Vector  | Exhaustive search (compares against all vectors)                            | ‚úÖ Exact         | ‚ùå Slow       | ‚ùå High       | O(N)                | Small datasets where precision is critical             |\n",
    "| **IVF**    | Vector  | Partitions vectors into clusters and searches only a few                    | ‚ö†Ô∏è Approximate   | ‚úÖ Fast       | ‚úÖ Medium     | O(N / K) or O(‚àöN)    | Mid-scale, good speed-accuracy trade-off               |\n",
    "| **HNSW**   | Vector  | Graph-based ANN with hierarchical layers and greedy traversal               | ‚úÖ Very High     | ‚úÖ Fastest    | ‚ùå High       | O(log N)            | High-scale, high-accuracy real-time search             |\n",
    "| **OPQ**    | Vector  | Compresses and rotates vectors for quantized fast search                    | ‚úÖ Higher than PQ| ‚úÖ Fast       | ‚úÖ Low        | O(log N)            | Billion-scale retrieval with constrained memory        |\n",
    "| **BM25**   | Lexical | Keyword-based search using TF-IDF + heuristics                              | ‚ùå No semantics  | ‚úÖ Fast       | ‚úÖ Low        | O(log N) or better  | Keyword search; good in hybrid with semantic vectors   |\n",
    "\n",
    "\n",
    "Hybrid search = **Lexical** search (keywords) + **Semantic** search (vector similarity)\n",
    "\n",
    "\n",
    "\n",
    "| Use Case                                | Use HNSW?                              |\n",
    "|-----------------------------------------|----------------------------------------|\n",
    "| Small data (<10k vectors)               | ‚ùå Not needed, use `FlatL2` or `FlatIP` |\n",
    "| Large data (>50k+ vectors)              | ‚úÖ Yes, faster retrieval                |\n",
    "| You want fast **approximate** retrieval | ‚úÖ Yes                                  |\n",
    "| You want exact similarity               | ‚ùå No, use `Flat*` indexes              |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01866d0",
   "metadata": {},
   "source": [
    "## B. FAISS\n",
    "\n",
    "**Index types**\n",
    "\n",
    "| FAISS Index       | Distance Metric | Description                                                             | Use Case                                               | Notes                                                                 |\n",
    "|-------------------|------------------|-------------------------------------------------------------------------|---------------------------------------------------------|-----------------------------------------------------------------------|\n",
    "| IndexFlatL2       | L2 (Euclidean)   | Computes exact Euclidean (squared) distance                             | Default for dense vectors (e.g., image, speech)         | Slower but highly accurate; scales poorly to large datasets           |\n",
    "| IndexFlatIP       | Inner Product    | Computes dot product between vectors                                    | Use with normalized vectors ‚Üí cosine similarity         | If embeddings are normalized, IP ‚âà cosine similarity                  |\n",
    "| IndexFlatL1       | L1 (Manhattan)   | Computes L1 (absolute value) distance                                   | Rarely used ‚Äî more common in sparse data or anomaly detection | FAISS supports it but with limited optimizations                      |\n",
    "| IndexFlat         | Depends on config| Deprecated ‚Äî avoid. Use one of the explicit ones like IndexFlatL2       | ‚ùå Do not use                                            |                                                                       |\n",
    "| IndexIVFFlat      | Any              | Inverted index + Flat inside clusters (needs training)                  | Large datasets with >100k vectors                       | Needs training with representative data                              |\n",
    "| IndexHNSWFlat     | Any              | Graph-based ANN with exact inner cluster distance                        | Fast + high recall for big datasets                     | Supports cosine similarity (with normalization)                      |\n",
    "| IndexPQ           | Compressed (L2)  | Product Quantization ‚Äî memory-efficient approximate search              | Billions of vectors                                     | Lower recall, fast, low memory                                       |\n",
    "\n",
    "\n",
    "**Distance Metrics**\n",
    "\n",
    "\n",
    "| Metric         | FAISS Index       | Formula                                       | Best For                          |\n",
    "|----------------|-------------------|-----------------------------------------------|-----------------------------------|\n",
    "| L2             | IndexFlatL2       | ||a - b||¬≤ (Euclidean)                        | Default for most dense vectors    |\n",
    "| L1             | IndexFlatL1       | sum(abs(a_i - b_i))                           | Sparse data / rare cases          |\n",
    "| Inner Product  | IndexFlatIP       | a ‚ãÖ b                                         | Use with normalized vectors       |\n",
    "| Cosine         | ‚âà IndexFlatIP + normalized embeddings | 1 - cos(Œ∏)                         | Semantic similarity (e.g., text)  |\n",
    "\n",
    "\n",
    "**Choosing strategy**\n",
    "\n",
    "| Goal                          | Recommended Index         | Notes                                                                 |\n",
    "|-------------------------------|----------------------------|-----------------------------------------------------------------------|\n",
    "| High accuracy, small dataset  | IndexFlatL2 or IndexFlatIP | Exact results, slow on big data                                       |\n",
    "| Semantic search (text)        | IndexFlatIP + normalize embeddings | IP ‚âà Cosine if vectors are unit-length                               |\n",
    "| Large dataset (>100k docs)    | IndexIVFFlat or IndexHNSWFlat | Fast ANN, need training (IVF) or parameter tuning (HNSW)             |\n",
    "| Memory-efficient search       | IndexPQ                    | Lower recall, but efficient                                           |\n",
    "| You care about diversity/novelty | IndexFlatIP + MMR         | Combine with MMR post-processing                                     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7522f118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a9360d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09a4aa11",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ‚úÖ 1. Load HuggingFace Embeddings\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_huggingface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceEmbeddings\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m embedding_model = \u001b[43mHuggingFaceEmbeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mBAAI/bge-base-en-v1.5\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdevice\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# or 'cuda' if you have GPU\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencode_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnormalize_embeddings\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# for cosine similarity\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# ‚úÖ 2. Load Chunks\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpickle\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\code\\projects\\gr\\.venv\\Lib\\site-packages\\langchain_huggingface\\embeddings\\huggingface.py:94\u001b[39m, in \u001b[36mHuggingFaceEmbeddings.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     92\u001b[39m     model_cls = sentence_transformers.SentenceTransformer\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28mself\u001b[39m._client = \u001b[43mmodel_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\code\\projects\\gr\\.venv\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:309\u001b[39m, in \u001b[36mSentenceTransformer.__init__\u001b[39m\u001b[34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data, backend)\u001b[39m\n\u001b[32m    300\u001b[39m         model_name_or_path = __MODEL_HUB_ORGANIZATION__ + \u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m + model_name_or_path\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sentence_transformer_model(\n\u001b[32m    303\u001b[39m     model_name_or_path,\n\u001b[32m    304\u001b[39m     token,\n\u001b[32m   (...)\u001b[39m\u001b[32m    307\u001b[39m     local_files_only=local_files_only,\n\u001b[32m    308\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m     modules, \u001b[38;5;28mself\u001b[39m.module_kwargs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_sbert_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    321\u001b[39m     modules = \u001b[38;5;28mself\u001b[39m._load_auto_model(\n\u001b[32m    322\u001b[39m         model_name_or_path,\n\u001b[32m    323\u001b[39m         token=token,\n\u001b[32m   (...)\u001b[39m\u001b[32m    330\u001b[39m         config_kwargs=config_kwargs,\n\u001b[32m    331\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\code\\projects\\gr\\.venv\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:1808\u001b[39m, in \u001b[36mSentenceTransformer._load_sbert_model\u001b[39m\u001b[34m(self, model_name_or_path, token, cache_folder, revision, trust_remote_code, local_files_only, model_kwargs, tokenizer_kwargs, config_kwargs)\u001b[39m\n\u001b[32m   1805\u001b[39m \u001b[38;5;66;03m# Try to initialize the module with a lot of kwargs, but only if the module supports them\u001b[39;00m\n\u001b[32m   1806\u001b[39m \u001b[38;5;66;03m# Otherwise we fall back to the load method\u001b[39;00m\n\u001b[32m   1807\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1808\u001b[39m     module = \u001b[43mmodule_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1809\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   1810\u001b[39m     module = module_class.load(model_name_or_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\code\\projects\\gr\\.venv\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:81\u001b[39m, in \u001b[36mTransformer.__init__\u001b[39m\u001b[34m(self, model_name_or_path, max_seq_length, model_args, tokenizer_args, config_args, cache_dir, do_lower_case, tokenizer_name_or_path, backend)\u001b[39m\n\u001b[32m     78\u001b[39m     config_args = {}\n\u001b[32m     80\u001b[39m config, is_peft_model = \u001b[38;5;28mself\u001b[39m._load_config(model_name_or_path, cache_dir, backend, config_args)\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_peft_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m max_seq_length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmodel_max_length\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m tokenizer_args:\n\u001b[32m     84\u001b[39m     tokenizer_args[\u001b[33m\"\u001b[39m\u001b[33mmodel_max_length\u001b[39m\u001b[33m\"\u001b[39m] = max_seq_length\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\code\\projects\\gr\\.venv\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:181\u001b[39m, in \u001b[36mTransformer._load_model\u001b[39m\u001b[34m(self, model_name_or_path, config, cache_dir, backend, is_peft_model, **model_args)\u001b[39m\n\u001b[32m    179\u001b[39m     \u001b[38;5;28mself\u001b[39m._load_mt5_model(model_name_or_path, config, cache_dir, **model_args)\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m     \u001b[38;5;28mself\u001b[39m.auto_model = \u001b[43mAutoModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_peft_model:\n\u001b[32m    186\u001b[39m     \u001b[38;5;28mself\u001b[39m._load_peft_model(model_name_or_path, config, cache_dir, **model_args, **adapter_only_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\code\\projects\\gr\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:571\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    569\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    570\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m571\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    575\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    576\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    577\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\code\\projects\\gr\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:309\u001b[39m, in \u001b[36mrestore_default_torch_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    307\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    311\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\code\\projects\\gr\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:4574\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4564\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   4565\u001b[39m         torch.set_default_dtype(dtype_orig)\n\u001b[32m   4567\u001b[39m     (\n\u001b[32m   4568\u001b[39m         model,\n\u001b[32m   4569\u001b[39m         missing_keys,\n\u001b[32m   4570\u001b[39m         unexpected_keys,\n\u001b[32m   4571\u001b[39m         mismatched_keys,\n\u001b[32m   4572\u001b[39m         offload_index,\n\u001b[32m   4573\u001b[39m         error_msgs,\n\u001b[32m-> \u001b[39m\u001b[32m4574\u001b[39m     ) = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4575\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4576\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4577\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4578\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4579\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4580\u001b[39m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4581\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4582\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4583\u001b[39m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4584\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4585\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4586\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4587\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4588\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4589\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4590\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4592\u001b[39m \u001b[38;5;66;03m# record tp degree the model sharded to\u001b[39;00m\n\u001b[32m   4593\u001b[39m model._tp_size = tp_size\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\code\\projects\\gr\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:5031\u001b[39m, in \u001b[36mPreTrainedModel._load_pretrained_model\u001b[39m\u001b[34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[39m\n\u001b[32m   5029\u001b[39m \u001b[38;5;66;03m# Skip it with fsdp on ranks other than 0\u001b[39;00m\n\u001b[32m   5030\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_fsdp_enabled() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_local_dist_rank_0() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_quantized):\n\u001b[32m-> \u001b[39m\u001b[32m5031\u001b[39m     disk_offload_index, cpu_offload_index = \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5032\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5033\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5034\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5035\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5036\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreverse_key_renaming_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5037\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5038\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5039\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisk_offload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5040\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcpu_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcpu_offload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5041\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcpu_offload_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcpu_offload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5042\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5043\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_offloaded_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5044\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5045\u001b[39m \u001b[43m        \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5046\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5047\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5049\u001b[39m \u001b[38;5;66;03m# force memory release if loading multiple shards, to avoid having 2 state dicts in memory in next loop\u001b[39;00m\n\u001b[32m   5050\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m state_dict\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\code\\projects\\gr\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\code\\projects\\gr\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:808\u001b[39m, in \u001b[36m_load_state_dict_into_meta_model\u001b[39m\u001b[34m(model, state_dict, shard_file, expected_keys, reverse_renaming_mapping, device_map, disk_offload_folder, disk_offload_index, cpu_offload_folder, cpu_offload_index, hf_quantizer, is_safetensors, keep_in_fp32_regex, unexpected_keys, device_mesh)\u001b[39m\n\u001b[32m    806\u001b[39m param = param[...]\n\u001b[32m    807\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m casting_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m808\u001b[39m     param = \u001b[43mparam\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasting_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    809\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m to_contiguous:\n\u001b[32m    810\u001b[39m     param = param.contiguous()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ‚úÖ 1. Load HuggingFace Embeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-base-en-v1.5\",\n",
    "    model_kwargs={'device': 'cpu'},  # or 'cuda' if you have GPU\n",
    "    encode_kwargs={'normalize_embeddings': True}  # for cosine similarity\n",
    ")\n",
    "\n",
    "# ‚úÖ 2. Load Chunks\n",
    "import pickle\n",
    "\n",
    "with open(\"data/chunks.pkl\", \"rb\") as f:\n",
    "    token_chunks = pickle.load(f)\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(token_chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6742d8a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'faiss' has no attribute 'IndexFlatL2'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ‚úÖ 3. Create FAISS Vector Store\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_community\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvectorstores\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FAISS\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m faiss_db = \u001b[43mFAISS\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_chunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_model\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ FAISS vector store created\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# ‚úÖ 4. Save FAISS to disk\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\code\\projects\\gr\\.venv\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:848\u001b[39m, in \u001b[36mVectorStore.from_documents\u001b[39m\u001b[34m(cls, documents, embedding, **kwargs)\u001b[39m\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ids):\n\u001b[32m    846\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mids\u001b[39m\u001b[33m\"\u001b[39m] = ids\n\u001b[32m--> \u001b[39m\u001b[32m848\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\code\\projects\\gr\\.venv\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:1044\u001b[39m, in \u001b[36mFAISS.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[32m   1026\u001b[39m \n\u001b[32m   1027\u001b[39m \u001b[33;03mThis is a user friendly interface that:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1041\u001b[39m \u001b[33;03m        faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[32m   1042\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1043\u001b[39m embeddings = embedding.embed_documents(texts)\n\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__from\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1045\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1046\u001b[39m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1047\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1048\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1049\u001b[39m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1050\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1051\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\code\\projects\\gr\\.venv\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:1001\u001b[39m, in \u001b[36mFAISS.__from\u001b[39m\u001b[34m(cls, texts, embeddings, embedding, metadatas, ids, normalize_L2, distance_strategy, **kwargs)\u001b[39m\n\u001b[32m    998\u001b[39m     index = faiss.IndexFlatIP(\u001b[38;5;28mlen\u001b[39m(embeddings[\u001b[32m0\u001b[39m]))\n\u001b[32m    999\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1000\u001b[39m     \u001b[38;5;66;03m# Default to L2, currently other metric types not initialized.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1001\u001b[39m     index = \u001b[43mfaiss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mIndexFlatL2\u001b[49m(\u001b[38;5;28mlen\u001b[39m(embeddings[\u001b[32m0\u001b[39m]))\n\u001b[32m   1002\u001b[39m docstore = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mdocstore\u001b[39m\u001b[33m\"\u001b[39m, InMemoryDocstore())\n\u001b[32m   1003\u001b[39m index_to_docstore_id = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mindex_to_docstore_id\u001b[39m\u001b[33m\"\u001b[39m, {})\n",
      "\u001b[31mAttributeError\u001b[39m: module 'faiss' has no attribute 'IndexFlatL2'"
     ]
    }
   ],
   "source": [
    "# ‚úÖ 3. Create FAISS Vector Store\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "faiss_db = FAISS.from_documents(\n",
    "    documents=token_chunks,\n",
    "    embedding=embedding_model\n",
    ")\n",
    "\n",
    "print(\"‚úÖ FAISS vector store created\")\n",
    "\n",
    "# ‚úÖ 4. Save FAISS to disk\n",
    "faiss_db.save_local(\"faiss_index\")\n",
    "print(\"‚úÖ FAISS index saved to 'faiss_index'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1388d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How does the model handle missing values?\"\n",
    "\n",
    "# Run a similarity search using MMR\n",
    "results = faiss_db.similarity_search_with_score(\n",
    "    query,\n",
    "    k=3,               # number of final documents\n",
    "    fetch_k=10,        # number of candidates to rerank from\n",
    "    lambda_mult=0.7,   # tradeoff between relevance and diversity\n",
    "    mmr=True\n",
    ")\n",
    "\n",
    "for doc, score in results:\n",
    "    print(f\"[{score:.4f}] {doc.page_content[:200]}...\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d70a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the main idea of the document?\"\n",
    "\n",
    "# Perform similarity search\n",
    "results = faiss_db.similarity_search(query, k=5)\n",
    "\n",
    "# Print results\n",
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(doc.page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb2c76d",
   "metadata": {},
   "source": [
    "Useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f46b9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_similarity_search_collection(collection_name: str, collection_metadata: dict = None):\n",
    "    \"\"\"Create ChromaDB collection with sentence transformer embeddings\"\"\"\n",
    "    try:\n",
    "        # Try to delete existing collection to start fresh\n",
    "        client.delete_collection(collection_name)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Create embedding function\n",
    "    sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "        model_name=\"all-MiniLM-L6-v2\"\n",
    "    )\n",
    "    \n",
    "    # Create new collection\n",
    "    return client.create_collection(\n",
    "        name=collection_name,\n",
    "        metadata=collection_metadata,\n",
    "        configuration={\n",
    "            \"hnsw\": {\"space\": \"cosine\"},\n",
    "            \"embedding_function\": sentence_transformer_ef\n",
    "        }\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
